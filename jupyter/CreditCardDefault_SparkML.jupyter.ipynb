{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1 id=\"tocheading\">Attrition Demo</h1>\n",
    "<div id=\"toc\"></div>\n",
    "\n",
    "<img src=\"https://github.com/elenalowery/DSX_Local_Workshop/blob/master/img/CC_Intro.JPG?raw=true\" width=\"800\" height=\"500\" align=\"middle\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "The Attrition demo focuses on retaining Merchants that are using company network for credit card processing. Here is the description of the case:\n",
    "\n",
    "A client approved many low value merchant accounts without much scrutiny.  Many of those merchant accounts resulted in default. The client thinks that they should have put more of an emphasis on their applicant screening process. IBM suggests to enable fact based decision making for performance of its joint marketing programs.\n",
    "\n",
    "This notebook will demostrate how to\n",
    "\n",
    "1. Use Brunel and Seaborn library for visualizations\n",
    "\n",
    "2. Use regular python Machine Learning libary scikit-learn and Spark's Machine Learning library(MLlib) for predicitive modeling in an intergrated environment on DSX.\n",
    "3. Deploy SparkML model using Machine Learning Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Run the following cell to import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "import brunel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy.stats import chi2_contingency,ttest_ind\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import urllib3, requests, json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load Customer History Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "# Add asset from file system\n",
    "cust_spark = SQLContext(sc).read.csv('../datasets/CUST_HISTORY.csv', header='true', inferSchema='true')\n",
    "cust_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create a Pandas DataFrame from the Spark DataFrame.  A Pandas DataFrame is required for the analysis below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cust_pd=cust_spark.toPandas()\n",
    "cust_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's take a quick look at the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print \"There are \" + str(len(cust_pd)) + \" observations in the customer history dataset.\"\n",
    "print \"There are \" + str(len(cust_pd.columns)) + \" variables in the dataset.\"\n",
    "\n",
    "print \"\\n******************Descriptive statistics*****************************\\n\"\n",
    "print cust_pd.describe()\n",
    "\n",
    "print \"\\n******************Dataset Quick View*****************************\\n\"\n",
    "cust_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "In this section, we will explore the dataset further with some visualizations.\n",
    "\n",
    "Two open source libraries are used:\n",
    "* <a href=\"https://github.com/Brunel-Visualization/Brunel\">Brunel</a> is a high-level language that describes visualizations in terms of composable actions. It drives a visualization engine (D3) that performs the actual rendering and interactivity. Brunel makes it much easier to build fun and inventive visualizations in Jupyter notebooks.\n",
    "\n",
    "* <a href=\"https://seaborn.pydata.org/\">Seaborn</a> is a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Outcome Variable: Account Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%brunel data('cust_pd') x(IS_DEFAULT) y(#count) color(IS_DEFAULT) bar tooltip(#all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As you can see from the bar chart, 300 out of 1000 accounts are in default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Default by Credit Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%brunel data('cust_pd') polar stack bar y(#count) color(CREDIT_PROGRAM) percent(#count) tooltip(#all) | stack bar x(CREDIT_PROGRAM) y(#count) color(IS_DEFAULT) bin(CREDIT_PROGRAM) percent(#count) label(#count) tooltip(#all) :: width=1200, height=350 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Top 3 credit programs with most Merchants are Electronics(28%), New Car(23.4%) and Furniture(18.1%).\n",
    "* Top 3 credit programs with high default rate are Education(44%), New Car(38%), and Retraining(35.1%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Default by IS_XBORDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%brunel data('cust_pd') polar stack bar y(#count) color(IS_XBORDER) percent(#count) tooltip(#all) | stack bar x(IS_XBORDER) y(#count) color(IS_DEFAULT) bin(IS_XBORDER) percent(#count) label(#count) tooltip(#all) :: width=1200, height=350 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Most Merchants have cross-border transactions. Relatively, they have a lower default rate than those don't have coross-border transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### RENT vs. IS_DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%brunel data('cust_pd') stack bar x(RENT) y(#count) color(IS_DEFAULT: blue-red) bin(RENT) sort(RENT) percent(#count) label(#count) tooltip(#all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "From this stacked bar chart, we can see that Merchants who rent their residence have higher default rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### HISTORY vs. IS_DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%brunel data('cust_pd') bar x(HISTORY) y(#count) color(HISTORY) tooltip(#all) | stack bar x(HISTORY) y(#count) color(IS_DEFAULT: green-red) bin(HISTORY) sort(HISTORY) percent(#count) label(#count) tooltip(#all) :: width=1200, height=350 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### AMOUNT_K_USD vs. IS_DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sub_yes = cust_pd[cust_pd[\"IS_DEFAULT\"] == \"Yes\"]\n",
    "sub_no = cust_pd[cust_pd[\"IS_DEFAULT\"] == \"No\"]\n",
    "    \n",
    "p_value = ttest_ind(sub_yes['AMOUNT_K_USD'], sub_no[\"AMOUNT_K_USD\"], equal_var = False)[1]\n",
    "\n",
    "fig, axs = plt.subplots(nrows= 1, figsize=(13, 5))\n",
    "sns.boxplot(x = \"IS_DEFAULT\", y = \"AMOUNT_K_USD\", data = cust_pd, showfliers=False, palette=\"Set2\")\n",
    "if p_value < .05:\n",
    "    plt.title(\"AMOUNT_K_USD\" + \"\\n P value:\" + str(p_value) + \"\\n The distributions for the two groups are significantly different!\" + \"\\n Default: mean/std.: \" + str(sub_yes[\"AMOUNT_K_USD\"].describe()[1]) + \"/\" + str(sub_yes[\"AMOUNT_K_USD\"].describe()[2]) + \"\\n Non-default: mean/std.: \" + str(sub_no[\"AMOUNT_K_USD\"].describe()[1]) + \"/\" + str(sub_no[\"AMOUNT_K_USD\"].describe()[2]))\n",
    "else:\n",
    "    plt.title(\"AMOUNT_K_USD\" + \"\\n P value:\" + str(p_value) + \"\\n Default: mean/std.: \" + str(sub_yes[\"AMOUNT_K_USD\"].describe()[1]) + \"/\" + str(sub_yes[\"AMOUNT_K_USD\"].describe()[2]) + \"\\n Non-default: mean/std.: \" + str(sub_safe[\"AMOUNT_K_USD\"].describe()[1]) + \"/\" + str(sub_no[\"AMOUNT_K_USD\"].describe()[2]))           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this box plot, the visualization is enhanced by T-test statistics. The result is significant which indicates that the average credit amount for the non-default group and default group are different. Default group has larger average credit amount.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Default rate by state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "default_rate = pd.crosstab(cust_pd.IS_DEFAULT, cust_pd.STATE).apply(lambda r: r/r.sum(), axis=0)\n",
    "\n",
    "default_rate2 = default_rate.T\n",
    "\n",
    "%brunel data('default_rate2') map color(Yes) key(STATE) label(STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Brunel also provides a very neat way for map visualization. So for this use case, all the Merchants come from 4 states: NY, NJ, PA and CT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Correlation Matrix\n",
    "\n",
    "A heatmap is used to visualize the correlations between all continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "corr_df = cust_pd.iloc[:,1:].corr()\n",
    "\n",
    "sns.heatmap(corr_df, \n",
    "            xticklabels = corr_df.columns.values,\n",
    "            yticklabels = corr_df.columns.values,\n",
    "            annot = True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* There is no strong correlation between most variables.\n",
    "* The correlation between AMOUNT_K_USD and CONTRACT_DURATION_MONTH is moderate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Modeling And Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For demo purpose, we will use RandomForestClassifier() from sklearn to rank feature importance, and Logistic Regression from Spark's Machine Learning Library(MLlib) for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Sklearn Random Forest: Rank Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert IS_DEFAULT to 1/0\n",
    "le = LabelEncoder()\n",
    "\n",
    "cust_pd_sk = cust_pd\n",
    "cust_pd_sk.loc[:,'IS_DEFAULT']= le.fit_transform(cust_pd_sk.loc[:,'IS_DEFAULT'])\n",
    "\n",
    "y = np.float32(cust_pd_sk.IS_DEFAULT)\n",
    "X = cust_pd.copy()\n",
    "\n",
    "# drop y \n",
    "X = cust_pd_sk.drop(['IS_DEFAULT', 'MERCHANT'], axis = 1)\n",
    "\n",
    "# Prepocess the data: Encode categorical variables into numeric representations\n",
    "\n",
    "categoricalColumns = [\"ACCT_STATUS_K_USD\", \"BRANCHES\",'HISTORY', 'CREDIT_PROGRAM', 'ACCOUNT_TYPE', 'ACCT_AGE', 'STATE', 'IS_URBAN', 'IS_XBORDER','SELF_REPORTED_ASMT', 'CO_APPLICANT', 'GUARANTOR','PRESENT_RESIDENT', 'OWN_REAL_ESTATE', 'PROP_UNKN','OTHER_INSTALL_PLAN', 'RENT', 'OWN_RESIDENCE','TELEPHONE', 'SHIP_INTERNATIONAL']\n",
    "\n",
    "for col in categoricalColumns:\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# scale X\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "\n",
    "# split the data to training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "#Stratify split and train on 5 folds\n",
    "skf = StratifiedKFold(y_train, n_folds=5)\n",
    "counter = 1\n",
    "for train_fold, test_fold in skf:\n",
    "    random_forest.fit(X_train[train_fold], y_train[train_fold])\n",
    "    \n",
    "    print( str(counter) + \": \", random_forest.score(X_train[test_fold], y_train[test_fold]))\n",
    "    counter += 1 \n",
    "    \n",
    "#### local notes: one interesting error here, if you don't do the import correctly, it will show error Params must be either a param map or a list/tuple of param maps, but got <class 'pandas.core.series.Series'>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "From the result of 5-fold CV, the average accuracy varies. The model is not very stable, one possible reason is that our sample size is really small. We will need to restrict the model complexity. We will choose top 10 important features for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "features_order = cust_pd_sk.drop(['IS_DEFAULT', 'MERCHANT'], axis = 1).columns.tolist()\n",
    "\n",
    "feature_importance_dict = {key: val for key, val in zip(features_order, random_forest.feature_importances_)}\n",
    "\n",
    "for k in sorted(feature_importance_dict, key=feature_importance_dict.get, reverse=True):\n",
    "    print k, feature_importance_dict[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Default Prediction: Spark MLlib Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this section, We will use Logistic Regression from Spark MLlib to predict defalut.<br/>\n",
    "We will use the Spark DataFrame for building the Spark ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cust_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Preprocess the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# group top 10 features to categorical and numerical\n",
    "allCols = cust_pd_sk.drop(['MERCHANT','IS_DEFAULT'], 1).columns.tolist()\n",
    "importantCols = ['AMOUNT_K_USD', 'ACCT_STATUS_K_USD', 'CONTRACT_DURATION_MONTH', 'ESTABLISHED_MONTH', 'HISTORY', 'CREDIT_PROGRAM', 'ACCT_AGE', 'ACCOUNT_TYPE', \"PRESENT_RESIDENT\", \"STATE\"]\n",
    "importantCols_num = ['AMOUNT_K_USD', 'CONTRACT_DURATION_MONTH', 'ESTABLISHED_MONTH']\n",
    "importantCols_cat = np.setdiff1d(importantCols, importantCols_num).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create label_str column\n",
    "cust_spark1 = cust_spark.withColumnRenamed(\"IS_DEFAULT\", 'label_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# One-hot encoder for all categorical varaibles\n",
    "for categoricalCol in importantCols_cat:\n",
    "    cust_spark1 = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\").fit(cust_spark1).transform(cust_spark1)\n",
    "    cust_spark1 = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\").transform(cust_spark1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Assemble feature vector\n",
    "assemblerInputs = map(lambda c: c + \"classVec\", importantCols_cat) + importantCols_num\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "cust_spark1 = assembler.transform(cust_spark1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Transform the label_str column to a numeric value\n",
    "cust_spark1 = StringIndexer(inputCol='label_str', outputCol='label').fit(cust_spark1).transform(cust_spark1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# keep useful variables\n",
    "selectedcols = [\"label\", \"features\"]\n",
    "cust_model = cust_spark1.select(selectedcols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Split the data into training and testing sets **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trainingData, testData = cust_model.randomSplit([0.7, 0.3], seed = 824)\n",
    "print trainingData.count()\n",
    "print testData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Train Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Use CrossValidator and ParamGridBuilder to search for best model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [1.0,0.3,0.1, 0.03,0.01,0.0]) \\\n",
    "    .addGrid(lr.fitIntercept, [False, True])\\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "    .build()\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "cvModel = cv.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Use BinaryClassificationEvaluator to evaluate the model**\n",
    "\n",
    "Note that the default metric for the BinaryClassificationEvaluator is *areaUnderROC*\n",
    "\n",
    "A rough guide for classifying the accuracy of a test:\n",
    "\n",
    "    .90-1 = excellent (A)\n",
    "    .80-.90 = good (B)\n",
    "    .70-.80 = fair (C)\n",
    "    .60-.70 = poor (D)\n",
    "    .50-.60 = fail (F)\n",
    "\n",
    "So the model performance is fair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "evaluator.evaluate(cvModel.transform(testData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Final Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will move forward with the model with Top 10 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Hyperparameters used in final model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print cvModel.bestModel._java_obj.getRegParam()\n",
    "print cvModel.bestModel._java_obj.getMaxIter()\n",
    "print cvModel.bestModel._java_obj.getElasticNetParam()\n",
    "print cvModel.bestModel._java_obj.getThreshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Intercept and Weights **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"Model Intercept = \" + str(cvModel.bestModel.intercept)\n",
    "\n",
    "coefficients = cvModel.bestModel.coefficients\n",
    "coefficients = map(lambda w: (float(w),), coefficients)\n",
    "weightsDF = sqlContext.createDataFrame(coefficients, [\"Feature Weight\"])\n",
    "weightsDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create Pipeline for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trainingData3, testData3 = cust_spark.randomSplit([0.7, 0.3], seed = 824)\n",
    "\n",
    "SI0 = StringIndexer(inputCol='IS_DEFAULT', outputCol=\"label\")\n",
    "SI1 = StringIndexer(inputCol='ACCOUNT_TYPE', outputCol='ACCOUNT_TYPE'+\"Index\")\n",
    "SI2 = StringIndexer(inputCol='ACCT_AGE', outputCol='ACCT_AGE'+\"Index\")\n",
    "SI3 = StringIndexer(inputCol='ACCT_STATUS_K_USD', outputCol='ACCT_STATUS_K_USD'+\"Index\")\n",
    "SI4 = StringIndexer(inputCol='CREDIT_PROGRAM', outputCol='CREDIT_PROGRAM'+\"Index\")\n",
    "SI5 = StringIndexer(inputCol='HISTORY', outputCol='HISTORY'+\"Index\")\n",
    "SI6 = StringIndexer(inputCol='PRESENT_RESIDENT', outputCol='PRESENT_RESIDENT'+\"Index\")\n",
    "SI7 = StringIndexer(inputCol='STATE', outputCol='STATE'+\"Index\")\n",
    "\n",
    "\n",
    "OH1 = OneHotEncoder(inputCol='ACCOUNT_TYPE'+\"Index\", outputCol='ACCOUNT_TYPE'+\"classVec\")\n",
    "OH2 = OneHotEncoder(inputCol='ACCT_AGE'+\"Index\", outputCol='ACCT_AGE'+\"classVec\")\n",
    "OH3 = OneHotEncoder(inputCol='ACCT_STATUS_K_USD'+\"Index\", outputCol='ACCT_STATUS_K_USD'+\"classVec\")\n",
    "OH4 = OneHotEncoder(inputCol='CREDIT_PROGRAM'+\"Index\", outputCol='CREDIT_PROGRAM'+\"classVec\")\n",
    "OH5 = OneHotEncoder(inputCol='HISTORY'+\"Index\", outputCol='HISTORY'+\"classVec\")\n",
    "OH6 = OneHotEncoder(inputCol='PRESENT_RESIDENT'+\"Index\", outputCol='PRESENT_RESIDENT'+\"classVec\")\n",
    "OH7 = OneHotEncoder(inputCol='STATE'+\"Index\", outputCol='STATE'+\"classVec\")\n",
    "\n",
    "assembler_features = VectorAssembler(inputCols=['ACCOUNT_TYPEclassVec','ACCT_AGEclassVec','ACCT_STATUS_K_USDclassVec','CREDIT_PROGRAMclassVec','HISTORYclassVec','PRESENT_RESIDENTclassVec', 'STATEclassVec',\n",
    " 'AMOUNT_K_USD',\n",
    " 'CONTRACT_DURATION_MONTH',\n",
    " 'ESTABLISHED_MONTH'], outputCol=\"features\")\n",
    "\n",
    "lr_final = LogisticRegression(maxIter=10, regParam=0.1, elasticNetParam=0.0, threshold = 0.5, labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline_lr = Pipeline(stages=[SI0,SI1, SI2, SI3,SI4,SI5,SI6,SI7, OH1,OH2,OH3,OH4,OH5,OH6,OH7, assembler_features, lr_final])\n",
    "model_lr = pipeline_lr.fit(trainingData3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Save Model in ML repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from dsx_ml.ml import save\n",
    "\n",
    "model_name = \"CreditCardDefault_model\"\n",
    "save(name = model_name,\n",
    "     model = model_lr,\n",
    "     algorithm_type = 'Classification',\n",
    "     test_data = testData3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Saved Model with Test UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "This step demonstrates an \"internal REST API\" call to test the model (for an unpublished model). Notice that we are using DSX variables for the model endpoint and token. See documentation for external REST call syntax. An exernal REST call will have a different end point and will require authentication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "json_payload =[{\n",
    "    \"MERCHANT\":999,\n",
    "    \"ACCT_STATUS_K_USD\":\"0 USD\",\n",
    "    \"CONTRACT_DURATION_MONTH\":12,\n",
    "    \"HISTORY\":\"CRITICAL ACCOUNT\",\n",
    "    \"CREDIT_PROGRAM\":\"NEW CAR\",\n",
    "    \"AMOUNT_K_USD\":2171,\n",
    "    \"ACCOUNT_TYPE\":\"up to 100 K USD\",\n",
    "    \"ACCT_AGE\":\"1 to 4 YRS\",\n",
    "    \"STATE\":\"NY\",\n",
    "    \"IS_URBAN\":\"NO\",\n",
    "    \"IS_XBORDER\":\"NO\",\n",
    "    \"SELF_REPORTED_ASMT\":\"NO\",\n",
    "    \"CO_APPLICANT\":\"YES\",\n",
    "    \"GUARANTOR\":\"NO\",\n",
    "    \"PRESENT_RESIDENT\":\"4\",\n",
    "    \"OWN_REAL_ESTATE\":\"NO\",\n",
    "    \"PROP_UNKN\":\"NO\",\n",
    "    \"ESTABLISHED_MONTH\":38,\n",
    "    \"OTHER_INSTALL_PLAN\":\"NO\",\n",
    "    \"RENT\":\"NO\",\n",
    "    \"OWN_RESIDENCE\":\"YES\",\n",
    "    \"NUMBER_CREDITS\":2,\n",
    "    \"RFM_SCORE\":2,\n",
    "    \"BRANCHES\":1,\n",
    "    \"TELEPHONE\":\"YES\",\n",
    "    \"SHIP_INTERNATIONAL\":\"NO\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Action Required**: Change the *scoring_endpoint* to the value that's shown as the *scoring_endpoint* afer running Save to ML repository function (see **Step 9**), for example *'scoring_endpoint': 'https://ibm-nginx-svc.ibm-private-cloud.svc.cluster.local/v3/project/score/Python27/spark-2.0/DSX_Local_Workshop_SidneyP/CreditCardDefault_model/1'*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests, json, os\n",
    "from pprint import pprint\n",
    "\n",
    "online_path = 'https://dsxl-api.ibm-private-cloud.svc.cluster.local/v3/project/score/Python27/spark-2.0/DSX_Local_Workshop_SidneyP/CreditCardDefault_model/2'\n",
    "\n",
    "header_online = {'Content-Type': 'application/json', 'Authorization':os.environ['DSX_TOKEN']}\n",
    "\n",
    "response_scoring = requests.post(online_path, json=json_payload, headers=header_online)\n",
    "\n",
    "response_scoring.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = response_scoring.json()['object']['output']['predictions'][0]\n",
    "print ('Prediction = {}'.format(prediction))\n",
    "probabilities = response_scoring.json()['object']['output']['probabilities'][0]\n",
    "print ('Probabilities = {}'.format(probabilities))\n",
    "if prediction == 0:\n",
    "    print('Prediction = No')\n",
    "    print('Probability = {0:.2f}'.format(probabilities[0]*100))\n",
    "elif prediction == 1:\n",
    "    print('Prediction = Yes')\n",
    "    print('Probability = {0:.2f}%'.format(probabilities[1]*100))\n",
    "else:\n",
    "    print('Probability ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You have finished working on this hands-on lab. In this notebook you have:\n",
    "1. Use Brunel and Seaborn library for visualizations\n",
    "\n",
    "2. Use regular python Machine Learning libary scikit-learn to build a RandomForestClassifier, and extracted the top 10 most important predictors\n",
    "3. Use Spark's Machine Learning library(MLlib) to build a LogisticRegression model with the top 10 most important predictors.\n",
    "4. Deploy SparkML model using Machine Learning Service\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Created by **Catherine Cao** and **Sidney Phoon**\n",
    "<br/>\n",
    "catherine.cao@ibm.com<br/>\n",
    "yfphoon@us.ibm.com<br/>\n",
    "\n",
    "Feb 12, 2018"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2 with Spark Local Mode",
   "language": "python",
   "name": "py2localspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
