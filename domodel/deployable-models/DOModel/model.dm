{"projectId":"RetailPlanning","modelId":"DOModel","decision":"New_Promotions","scenario":"Scenario 2","name":"DOModel","author":{"name":"nerav"},"inputSchemas":[{"name":"Offer","type":"struct","fields":[{"name":"offer id","type":"double","nullable":true},{"name":"offer","type":"string","nullable":true}]},{"name":"Customer","type":"struct","fields":[{"name":"Customer ID","type":"double","nullable":true},{"name":"Offer id","type":"double","nullable":true},{"name":"Offer","type":"string","nullable":true},{"name":"Offer_Probability","type":"double","nullable":true},{"name":"Target Channel","type":"string","nullable":true},{"name":"Revenue","type":"double","nullable":true},{"name":"CostToServ","type":"double","nullable":true}]}],"outputSchemas":[{"name":"kpis","type":"struct","fields":[{"name":"Name","type":"string","nullable":true},{"name":"Value","type":"double","nullable":true},{"name":"Slider","type":"double","nullable":true},{"name":"Weight factor","type":"double","nullable":true},{"name":"Scale factor","type":"double","nullable":true},{"name":"Scaled weighted value","type":"double","nullable":true}]},{"name":"list_of_Customer_solution","type":"struct","fields":[{"name":"id_of_Customer","type":"double","nullable":true},{"name":"selectionVar","type":"double","nullable":true}]},{"name":"Customer_selection_report","type":"struct","fields":[{"name":"Customer __line","type":"string","nullable":true},{"name":"Customer CostToServ","type":"double","nullable":true},{"name":"Customer Customer ID","type":"double","nullable":true},{"name":"Customer Offer id","type":"double","nullable":true},{"name":"Customer Offer_Probability","type":"double","nullable":true},{"name":"Customer Revenue","type":"double","nullable":true},{"name":"Customer Offer","type":"string","nullable":true},{"name":"Customer Target Channel","type":"string","nullable":true},{"name":"total Revenue of Customers over all selections","type":"double","nullable":true},{"name":"total CostToServ of Customers over all selections","type":"double","nullable":true}]}],"modelCode":[{"name":"model.py","code":"from docplex.mp.model import *\nfrom docplex.mp.utils import *\nfrom docloud.status import JobSolveStatus\nfrom docplex.mp.conflict_refiner import ConflictRefiner, VarUbConstraintWrapper, VarLbConstraintWrapper\nfrom docplex.mp.relaxer import Relaxer\nimport time\nimport sys\nimport operator\n\nimport pandas as pd\nimport numpy as np\nimport math\n\nimport codecs\nimport sys\n\n# Handle output of unicode strings\nif sys.version_info[0] < 3:\n    sys.stdout = codecs.getwriter('utf8')(sys.stdout)\n\n\n# Label constraint\ndef helper_add_labeled_cplex_constraint(mdl, expr, label, context=None, columns=None):\n    global expr_counter\n    if isinstance(expr, bool):\n        pass  # Adding a trivial constraint: if infeasible, docplex will raise an exception it is added to the model\n    else:\n        expr.name = '_L_EXPR_' + str(len(expr_to_info) + 1)\n        if columns:\n            ctxt = \", \".join(str(getattr(context, col)) for col in columns)\n        else:\n            if context:\n                ctxt = context.Index if isinstance(context.Index, str) is not None else \", \".join(context.Index)\n            else:\n                ctxt = None\n        expr_to_info[expr.name] = (label, ctxt)\n    mdl.add(expr)\n\ndef helper_get_column_name_for_property(property):\n    return helper_property_id_to_column_names_map.get(property, 'unknown')\n\n\ndef helper_get_index_names_for_type(dataframe, type):\n    if not is_pandas_dataframe(dataframe):\n        return None\n    return [name for name in dataframe.index.names if name in helper_concept_id_to_index_names_map.get(type, [])]\n\n\nhelper_concept_id_to_index_names_map = {\n    'cItem': ['id_of_Customer'],\n    'Customer': ['id_of_Customer']}\nhelper_property_id_to_column_names_map = {\n    'Customer.CostToServ': 'CostToServ',\n    'Customer.Offer id': 'Offer_id',\n    'Customer.Revenue': 'Revenue'}\n\n\n# Data model definition for each table\n# Data collection: list_of_Customer ['CostToServ', 'Offer_id', 'Revenue', '__line']\n\n# Create a pandas Dataframe for each data table\nlist_of_Customer = inputs[u'Customer']\nlist_of_Customer = list_of_Customer[[u'CostToServ', u'Offer id', u'Revenue']].copy()\nlist_of_Customer.rename(columns={u'CostToServ': 'CostToServ', u'Offer id': 'Offer_id', u'Revenue': 'Revenue'}, inplace=True)\n\n# Set index when a primary key is defined\nlist_of_Customer.index.name = 'id_of_Customer'\n\n\n\n\n\n\ndef build_model():\n    mdl = Model()\n\n    # Definition of model variables\n    list_of_Customer['selectionVar'] = mdl.binary_var_list(len(list_of_Customer))\n\n\n    # Definition of model\n    # Objective cMaximizeGoalSelect-\n    # Combine weighted criteria: \n    # \tcMaximizeGoalSelect cMaximizeGoalSelect 1.2{\n    # \tcSingleCriterionGoal.numericExpr = total cSelection[Customer] / Customer / Revenue,\n    # \tcScaledGoal.scaleFactorExpr = 1,\n    # \tcSingleCriterionGoal.goalFilter = null} with weight 5.0\n    # \tcMinimizeGoalSelect cMinimizeGoalSelect 1.2{\n    # \tcSingleCriterionGoal.numericExpr = total cSelection[Customer] / Customer / CostToServ,\n    # \tcScaledGoal.scaleFactorExpr = 1,\n    # \tcSingleCriterionGoal.goalFilter = null} with weight 5.0\n    list_of_Customer['conditioned_Revenue'] = list_of_Customer.selectionVar * list_of_Customer.Revenue\n    agg_Customer_conditioned_Revenue_SG1 = mdl.sum(list_of_Customer.conditioned_Revenue)\n    list_of_Customer['conditioned_CostToServ'] = list_of_Customer.selectionVar * list_of_Customer.CostToServ\n    agg_Customer_conditioned_CostToServ_SG2 = mdl.sum(list_of_Customer.conditioned_CostToServ)\n    \n    kpis_expression_list = [\n        (-1, 16.0, agg_Customer_conditioned_Revenue_SG1, 1, 0, u'total Revenue of Customers over all selections'),\n        (1, 16.0, agg_Customer_conditioned_CostToServ_SG2, 1, 0, u'total CostToServ of Customers over all selections')]\n    custom_code.update_goals_list(kpis_expression_list)\n    \n    for _, kpi_weight, kpi_expr, kpi_factor, kpi_offset, kpi_name in kpis_expression_list:\n        mdl.add_kpi(kpi_weight * ((kpi_expr * kpi_factor) - kpi_offset), publish_name=kpi_name)\n    \n    mdl.minimize(sum([kpi_sign * kpi_weight * ((kpi_expr * kpi_factor) - kpi_offset) for kpi_sign, kpi_weight, kpi_expr, kpi_factor, kpi_offset, kpi_name in kpis_expression_list]))\n    \n    # [ST_1] Constraint : cIterativeRelationalConstraint_cIterativeRelationalConstraint\n    # For each Customer selection, Offer id of selected Customer is less than or equal to 2\n    # Label: CT_1_For_each_Customer_selection__Offer_id_of_selected_Customer_is_less_than_or_equal_to_2\n    list_of_Customer['conditioned_Offer_id'] = list_of_Customer.selectionVar * list_of_Customer.Offer_id\n    for row in list_of_Customer.itertuples(index=True):\n        helper_add_labeled_cplex_constraint(mdl, row.conditioned_Offer_id <= 2, u'For each Customer selection, Offer id of selected Customer is less than or equal to 2', row)\n    \n    # [ST_2] Constraint : cGlobalRelationalConstraint_cGlobalRelationalConstraint\n    # total CostToServ of Customers over all selections is less than 200000\n    # Label: CT_2_total_CostToServ_of_Customers_over_all_selections_is_less_than_200000\n    list_of_Customer['conditioned_CostToServ'] = list_of_Customer.selectionVar * list_of_Customer.CostToServ\n    agg_Customer_conditioned_CostToServ_lhs = mdl.sum(list_of_Customer.conditioned_CostToServ)\n    helper_add_labeled_cplex_constraint(mdl, agg_Customer_conditioned_CostToServ_lhs <= -0.001 + 200000, u'total CostToServ of Customers over all selections is less than 200000')\n    \n    # [ST_3] Constraint : cGlobalRelationalConstraint_cGlobalRelationalConstraint\n    # total Revenue of Customers over all selections is greater than 300000\n    # Label: CT_3_total_Revenue_of_Customers_over_all_selections_is_greater_than_300000\n    list_of_Customer['conditioned_Revenue'] = list_of_Customer.selectionVar * list_of_Customer.Revenue\n    agg_Customer_conditioned_Revenue_lhs = mdl.sum(list_of_Customer.conditioned_Revenue)\n    helper_add_labeled_cplex_constraint(mdl, agg_Customer_conditioned_Revenue_lhs >= 0.001 + 300000, u'total Revenue of Customers over all selections is greater than 300000')\n\n\n    return mdl\n\n\ndef solve_model(mdl):\n    mdl.parameters.timelimit = 120\n    # Call to custom code to update parameters value\n    custom_code.update_solver_params(mdl.parameters)\n    # Update parameters value based on environment variables definition\n    cplex_param_env_prefix = 'ma.cplex.'\n    cplex_params = [name.qualified_name for name in mdl.parameters.generate_params()]\n    for param in cplex_params:\n        env_param = cplex_param_env_prefix + param\n        param_value = get_environment().get_parameter(env_param)\n        if param_value:\n            # Updating parameter value\n            print(\"Updated value for parameter %s = %s\" % (param, param_value))\n            parameters = mdl.parameters\n            for p in param.split('.')[1:]:\n                parameters = parameters.__getattribute__(p)\n            parameters.set(param_value)\n\n    msol = mdl.solve(log_output=True)\n    if not msol:\n        print(\"!!! Solve of the model fails\")\n        if mdl.get_solve_status() == JobSolveStatus.INFEASIBLE_SOLUTION or mdl.get_solve_status() == JobSolveStatus.INFEASIBLE_OR_UNBOUNDED_SOLUTION:\n            crefiner = ConflictRefiner()\n            conflicts = crefiner.refine_conflict(model, log_output=True)\n            export_conflicts(conflicts)\n            \n    print('Solve status: %s' % mdl.get_solve_status())\n    mdl.report()\n    return msol\n\n\nexpr_to_info = {}\n\n\ndef export_conflicts(conflicts):\n    # Display conflicts in console\n    print('Conflict set:')\n    list_of_conflicts = pd.DataFrame(columns=['constraint', 'context', 'detail'])\n    for conflict, index in zip(conflicts, range(len(conflicts))):\n        st = conflict.status\n        ct = conflict.element\n        label, context = expr_to_info.get(conflict.name, ('N/A', conflict.name))\n        label_type = type(conflict.element)\n        if isinstance(conflict.element, VarLbConstraintWrapper) \\\n                or isinstance(conflict.element, VarUbConstraintWrapper):\n            label = 'Upper/lower bound conflict for variable: {}'.format(conflict.element._var)\n            context = 'Decision variable definition'\n            ct = conflict.element.get_constraint()\n\n        # Print conflict information in console\n        print(\"Conflict involving constraint: %s, \\tfor: %s -> %s\" % (label, context, ct))\n        list_of_conflicts = list_of_conflicts.append({'constraint': label, 'context': str(context), 'detail': ct},\n                                                     ignore_index=True)\n\n    # Update of the ``outputs`` dict must take the 'Lock' to make this action atomic,\n    # in case the job is aborted\n    global output_lock\n    with output_lock:\n        outputs['list_of_conflicts'] = list_of_conflicts\n\n\ndef export_solution(msol):\n    start_time = time.time()\n    list_of_Customer_solution = pd.DataFrame(index=list_of_Customer.index)\n    list_of_Customer_solution['selectionVar'] = msol.get_values(list_of_Customer.selectionVar.values)\n\n    # Update of the ``outputs`` dict must take the 'Lock' to make this action atomic,\n    # in case the job is aborted\n    global output_lock\n    with output_lock:\n        outputs['list_of_Customer_solution'] = list_of_Customer_solution.reset_index()\n        custom_code.post_process_solution(msol, outputs)\n\n    elapsed_time = time.time() - start_time\n    print('solution export done in ' + str(elapsed_time) + ' secs')\n    return\n\n\n# Instantiate CustomCode class if definition exists\ntry:\n    custom_code = CustomCode(globals())\nexcept NameError:\n    # Create a dummy anonymous object for custom_code\n    custom_code = type('', (object,), {'preprocess': (lambda *args: None),\n                                       'update_goals_list': (lambda *args: None),\n                                       'update_model': (lambda *args: None),\n                                       'update_solver_params': (lambda *args: None),\n                                       'post_process_solution': (lambda *args: None)})()\n\n# Custom pre-process\ncustom_code.preprocess()\n\nprint('* building wado model')\nstart_time = time.time()\nmodel = build_model()\n\n# Model customization\ncustom_code.update_model(model)\n\nelapsed_time = time.time() - start_time\nprint('model building done in ' + str(elapsed_time) + ' secs')\n\nprint('* running wado model')\nstart_time = time.time()\nmsol = solve_model(model)\nelapsed_time = time.time() - start_time\nprint('model solve done in ' + str(elapsed_time) + ' secs')\nif msol:\n    export_solution(msol)\n"},{"name":"main.py","code":"from functools import partial, wraps\r\nimport os\r\nfrom os.path import splitext\r\nimport time\r\nimport threading\r\nimport traceback\r\nimport sys\r\n\r\nimport pandas\r\nfrom six import iteritems\r\n\r\nfrom docplex.util.environment import get_environment\r\n\r\noutput_lock = threading.Lock()\r\n\r\n\r\ndef set_stop_callback(cb):\r\n    env = get_environment()\r\n    env.abort_callbacks += [cb]\r\n\r\n\r\ndef get_all_inputs():\r\n    '''Utility method to read a list of files and return a tuple with all\r\n    read data frames.\r\n    Returns:\r\n        a map { datasetname: data frame }\r\n    '''\r\n    result = {}\r\n    env = get_environment()\r\n    for iname in [f for f in os.listdir('.') if splitext(f)[1] == '.csv']:\r\n        with env.get_input_stream(iname) as in_stream:\r\n            df = pandas.read_csv(in_stream)\r\n            datasetname, _ = splitext(iname)\r\n            result[datasetname] = df\r\n    return result\r\n\r\n\r\ndef callonce(f):\r\n    @wraps(f)\r\n    def wrapper(*args, **kwargs):\r\n        if not wrapper.called:\r\n            wrapper.called = True\r\n            return f(*args, **kwargs)\r\n    wrapper.called = False\r\n    return wrapper\r\n\r\n\r\n@callonce\r\ndef write_all_outputs(outputs):\r\n    '''Write all dataframes in ``outputs`` as .csv.\r\n\r\n    Args:\r\n        outputs: The map of outputs 'outputname' -> 'output df'\r\n    '''\r\n    global output_lock\r\n    with output_lock:\r\n        for (name, df) in iteritems(outputs):\r\n            csv_file = '%s.csv' % name\r\n            with get_environment().get_output_stream(csv_file) as fp:\r\n                if sys.version_info[0] < 3:\r\n                    fp.write(df.to_csv(index=False, encoding='utf8'))\r\n                else:\r\n                    fp.write(df.to_csv(index=False).encode(encoding='utf8'))\r\n    if len(outputs) == 0:\r\n        print(\"Warning: no outputs written\")\r\n\r\n\r\ndef wait_and_save_all_cb(outputs):\r\n    global output_lock\r\n    # just wait for the output_lock to be available\r\n    t = time.time()\r\n    with output_lock:\r\n        pass\r\n    elapsed = time.time() - t\r\n    # write outputs\r\n    write_all_outputs(outputs)\r\n\r\n\r\ndef get_line_of_model(n):\r\n    env = get_environment()\r\n    with env.get_input_stream('model.py') as m:\r\n        lines = m.readlines()\r\n        return lines[n - 1]\r\n\r\n\r\nclass InterpreterError(Exception):\r\n    pass\r\n\r\nif __name__ == '__main__':\r\n    inputs = get_all_inputs()\r\n    outputs = {}\r\n    set_stop_callback(partial(wait_and_save_all_cb, outputs))\r\n\r\n    env = get_environment()\r\n    # The IS_DODS env must be True for model.py if running in DODS\r\n    os.environ['IS_DODS'] = 'True'\r\n    # This allows docplex.mp to behave the same (publish kpis.csv and solution.json\r\n    # if this script is run locally\r\n    os.environ['DOCPLEX_CONTEXT'] = 'solver.auto_publish=True'\r\n    with env.get_input_stream('model.py') as m:\r\n        try:\r\n            exec(m.read().decode('utf-8'), globals())\r\n        except SyntaxError as err:\r\n            error_class = err.__class__.__name__\r\n            detail = err.args[0]\r\n            line_number = err.lineno\r\n            imsg = 'File \"model.py\", line %s\\n' % line_number\r\n            imsg += err.text.rstrip() + '\\n'\r\n            spaces = ' ' * (err.offset - 1) if err.offset > 1 else ''\r\n            imsg += spaces + \"^\\n\"\r\n            imsg += '%s: %s\\n' % (error_class, detail)\r\n            raise InterpreterError(imsg)\r\n        except Exception as err:\r\n            error_class = err.__class__.__name__\r\n            detail = err.args[0]\r\n            cl, exc, tb = sys.exc_info()\r\n            ttb = traceback.extract_tb(tb)\r\n            ttb[1] = ('model.py', ttb[1][1], ttb[1][2],\r\n                      get_line_of_model(ttb[1][1]))\r\n            line_number = ttb[1][1]\r\n            ttb = ttb[1:]\r\n            s = traceback.format_list(ttb)\r\n            imsg = (''.join(s))\r\n            imsg += '%s: %s\\n' % (error_class, detail)\r\n            raise InterpreterError(imsg)\r\n        else:\r\n            write_all_outputs(outputs)\r\n\r\n"}],"solveParameters":{},"dateCreated":1569006013409}